{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®ç»´åº¦: (44, 7)\n",
      "æ•°æ®å‰å‡ è¡Œ: \n",
      "    KH550 (volume/mL)  temperature (â„ƒ)  Reaction time (h)  \\\n",
      "0                0.1               90                 12   \n",
      "1                0.5               90                 12   \n",
      "2                1.0               90                 12   \n",
      "3                1.5               90                 12   \n",
      "4                2.0               90                 12   \n",
      "\n",
      "   Protein incubation time (h)  Imidazole concentration (mM)  \\\n",
      "0                          2.0                           500   \n",
      "1                          2.0                           500   \n",
      "2                          2.0                           500   \n",
      "3                          2.0                           500   \n",
      "4                          2.0                           500   \n",
      "\n",
      "   Volume of imidazole (Î¼L)  width (mm)  \n",
      "0                       600         0.3  \n",
      "1                       600         0.5  \n",
      "2                       600         0.5  \n",
      "3                       600         0.8  \n",
      "4                       600         1.0  \n",
      "Training ExtraTrees...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best parameters for ExtraTrees: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Training AdaBoost...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters for AdaBoost: {'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 200}\n",
      "Training RandomForest...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best parameters for RandomForest: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "Training GradientBoosting...\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best parameters for GradientBoosting: {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training KNN...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters for KNN: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "              Model        RÂ²       MAE      RMSE        EV\n",
      "0        ExtraTrees  0.887536  0.266177  0.360497  0.933032\n",
      "1          AdaBoost  0.935361  0.222322  0.273302  0.950940\n",
      "2      RandomForest  0.898004  0.273904  0.343310  0.923192\n",
      "3  GradientBoosting  0.810009  0.369483  0.468556  0.812810\n",
      "4               KNN  0.823090  0.363517  0.452138  0.846229\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r'E:\\Desktop\\è®ºæ–‡\\è«æ„å¸ˆå§\\ç£æ€§æ°§åŒ–é“åˆ†ç¦»è›‹ç™½(6).csv'\n",
    "df = pd.read_csv(file_path, encoding='gbk')  # å°è¯•ä½¿ç”¨ GBK ç¼–ç \n",
    "print('æ•°æ®ç»´åº¦:', df.shape)\n",
    "# æ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "data_path = r'E:\\Desktop\\è®ºæ–‡\\è«æ„å¸ˆå§\\ç£æ€§æ°§åŒ–é“åˆ†ç¦»è›‹ç™½(6).csv'\n",
    " \n",
    "# åŠ è½½æ•°æ®\n",
    "data = pd.read_csv(data_path, encoding='gbk')\n",
    " \n",
    "# åˆ’åˆ†ç‰¹å¾å’Œæ ‡ç­¾\n",
    "X = data.iloc[:, :-1]  # ä»ç¬¬ä¸€åˆ—åˆ°å€’æ•°ç¬¬äºŒåˆ—æå–ç‰¹å¾\n",
    "y = data.iloc[:, -1]   # æœ€åä¸€åˆ—ä½œä¸ºç›®æ ‡å˜é‡\n",
    "# ç¡®ä¿æ‰€æœ‰ç‰¹å¾åç§°éƒ½æ˜¯å­—ç¬¦ä¸²å¹¶ç§»é™¤ç‰¹æ®Šå­—ç¬¦\n",
    "df.columns = df.columns.astype(str).str.replace('[', '', regex=False).str.replace(']', '', regex=False).str.replace('<', '', regex=False)\n",
    "\n",
    "# æ‰“å°å‰å‡ è¡Œæ•°æ®\n",
    "print(\"æ•°æ®å‰å‡ è¡Œ: \\n\", df.head())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2048)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "\n",
    "# å®šä¹‰æ¨¡å‹ï¼ˆæ–°å¢ KNN å’Œ SVRï¼‰\n",
    "models = {\n",
    "    'ExtraTrees': ExtraTreesRegressor(random_state=2048),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=2048),\n",
    "    'RandomForest': RandomForestRegressor(random_state=2048),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=2048),\n",
    "    'KNN': KNeighborsRegressor(),           # æ–°å¢ KNN\n",
    "}\n",
    "\n",
    "# è¶…å‚æ•°ç½‘æ ¼ï¼ˆæ–°å¢ KNN å’Œ SVRï¼‰\n",
    "param_grids = {\n",
    "    'ExtraTrees': {\n",
    "        'n_estimators': [10, 20, 100],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'max_depth': [None, 5, 10, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2, 1.0],\n",
    "        'loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "}\n",
    "\n",
    "# å­˜å‚¨ç»“æœ\n",
    "results = []\n",
    "\n",
    "# éå†æ¨¡å‹ï¼Œè°ƒå‚ä¸è¯„ä¼°\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # ç½‘æ ¼æœç´¢\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # æœ€ä¼˜æ¨¡å‹å’Œå‚æ•°\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "\n",
    "    # é¢„æµ‹\n",
    "    y_pred_test = best_estimator.predict(X_test)\n",
    "\n",
    "    # è®¡ç®— Root MAPEï¼ˆé¿å…é™¤ä»¥ 0ï¼‰\n",
    "    non_zero_idx = y_test != 0\n",
    "    if np.any(non_zero_idx):\n",
    "        mape = np.mean(np.abs((y_test[non_zero_idx] - y_pred_test[non_zero_idx]) / y_test[non_zero_idx])) * 100\n",
    "        root_mape = np.sqrt(mape)  # è®¡ç®—å‡æ–¹æ ¹ MAPE\n",
    "    else:\n",
    "        root_mape = np.nan\n",
    "\n",
    "    # è®¡ç®—å…¶ä»–æŒ‡æ ‡\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    ev = explained_variance_score(y_test, y_pred_test)\n",
    "\n",
    "    # å­˜å‚¨ç»“æœ\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'RÂ²': r2,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'EV': ev\n",
    "    })\n",
    "\n",
    "# è½¬æ¢ä¸º DataFrame å±•ç¤º\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# æ‰“å°ç»“æœ\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®ç»´åº¦: (44, 7)\n",
      "\n",
      "ğŸš€ æ­£åœ¨é‡æ–°è®­ç»ƒ ExtraTrees...\n",
      "âœ… é‡æ–°è®­ç»ƒçš„ ExtraTrees å·²ä¿å­˜åˆ° E:\\Desktop\\è«æ„å¸ˆå§å¹³å°éƒ¨ç½²\\è®­ç»ƒæ¨¡å‹\\ExtraTrees_optimized_model.pkl\n",
      "\n",
      "ğŸš€ æ­£åœ¨é‡æ–°è®­ç»ƒ AdaBoost...\n",
      "âœ… é‡æ–°è®­ç»ƒçš„ AdaBoost å·²ä¿å­˜åˆ° E:\\Desktop\\è«æ„å¸ˆå§å¹³å°éƒ¨ç½²\\è®­ç»ƒæ¨¡å‹\\AdaBoost_optimized_model.pkl\n",
      "\n",
      "ğŸš€ æ­£åœ¨é‡æ–°è®­ç»ƒ RandomForest...\n",
      "âœ… é‡æ–°è®­ç»ƒçš„ RandomForest å·²ä¿å­˜åˆ° E:\\Desktop\\è«æ„å¸ˆå§å¹³å°éƒ¨ç½²\\è®­ç»ƒæ¨¡å‹\\RandomForest_optimized_model.pkl\n",
      "\n",
      "ğŸš€ æ­£åœ¨é‡æ–°è®­ç»ƒ GradientBoosting...\n",
      "âœ… é‡æ–°è®­ç»ƒçš„ GradientBoosting å·²ä¿å­˜åˆ° E:\\Desktop\\è«æ„å¸ˆå§å¹³å°éƒ¨ç½²\\è®­ç»ƒæ¨¡å‹\\GradientBoosting_optimized_model.pkl\n",
      "\n",
      "ğŸš€ æ­£åœ¨é‡æ–°è®­ç»ƒ KNN...\n",
      "âœ… é‡æ–°è®­ç»ƒçš„ KNN å·²ä¿å­˜åˆ° E:\\Desktop\\è«æ„å¸ˆå§å¹³å°éƒ¨ç½²\\è®­ç»ƒæ¨¡å‹\\KNN_optimized_model.pkl\n",
      "\n",
      "âœ… è®­ç»ƒç»“æœå·²ä¿å­˜åˆ° Excel æ–‡ä»¶ï¼\n",
      "\n",
      "âœ… è®­ç»ƒç‰¹å¾ä¿¡æ¯å·²ä¿å­˜åˆ° training_feature_info.xlsx\n",
      "\n",
      "âœ… å·²æˆåŠŸä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ï¼š ['AdaBoost_optimized_model.pkl', 'ExtraTrees_optimized_model.pkl', 'GradientBoosting_optimized_model.pkl', 'KNN_optimized_model.pkl', 'model_training_results.xlsx', 'RandomForest_optimized_model.pkl', 'training_feature_info.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# é‡æ–°åŠ è½½å¿…è¦çš„åº“\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "file_path = r'E:\\Desktop\\è®ºæ–‡\\è«æ„å¸ˆå§\\ç£æ€§æ°§åŒ–é“åˆ†ç¦»è›‹ç™½(6).csv'\n",
    "df = pd.read_csv(file_path, encoding='gbk')  # å°è¯•ä½¿ç”¨ GBK ç¼–ç \n",
    "print('æ•°æ®ç»´åº¦:', df.shape)\n",
    "# æ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "data_path = r'E:\\Desktop\\è®ºæ–‡\\è«æ„å¸ˆå§\\ç£æ€§æ°§åŒ–é“åˆ†ç¦»è›‹ç™½(6).csv'\n",
    "\n",
    "# ğŸ“Œ 2ï¸âƒ£ ç¡®ä¿æ­£ç¡®åˆ’åˆ† 6 ä¸ªç‰¹å¾å’Œ 1 ä¸ªç›®æ ‡å˜é‡\n",
    "X = df.iloc[:, :-1]  # å‰ 6 åˆ—æ˜¯ç‰¹å¾\n",
    "y = df.iloc[:, -1]   # æœ€åä¸€åˆ—æ˜¯ç›®æ ‡å˜é‡ (width mm)\n",
    "\n",
    "# ğŸ“Œ 3ï¸âƒ£ åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ğŸ“Œ 4ï¸âƒ£ ä½¿ç”¨æ‰¾åˆ°çš„æœ€ä¼˜å‚æ•°é‡æ–°è®­ç»ƒæ¨¡å‹\n",
    "optimal_models = {\n",
    "    'ExtraTrees': ExtraTreesRegressor(\n",
    "        max_depth=10, max_features='sqrt', min_samples_leaf=1, min_samples_split=2, n_estimators=10, random_state=2048\n",
    "    ),\n",
    "    'AdaBoost': AdaBoostRegressor(\n",
    "        learning_rate=0.01, loss='square', n_estimators=200, random_state=2048\n",
    "    ),\n",
    "    'RandomForest': RandomForestRegressor(\n",
    "        bootstrap=False, max_depth=None, max_features='sqrt', min_samples_leaf=1, min_samples_split=5, n_estimators=500, random_state=2048\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingRegressor(\n",
    "        learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100, random_state=2048\n",
    "    ),\n",
    "    'KNN': KNeighborsRegressor(\n",
    "        n_neighbors=3, p=1, weights='distance'\n",
    "    ),\n",
    "}\n",
    "\n",
    "# ğŸ“Œ 5ï¸âƒ£ å®šä¹‰æ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "save_path = \"E:\\Desktop\\è«æ„å¸ˆå§å¹³å°éƒ¨ç½²\\è®­ç»ƒæ¨¡å‹\"\n",
    "os.makedirs(save_path, exist_ok=True)  # åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰\n",
    "\n",
    "# ğŸ“Œ 6ï¸âƒ£ é‡æ–°è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹\n",
    "for model_name, model in optimal_models.items():\n",
    "    print(f\"\\nğŸš€ æ­£åœ¨é‡æ–°è®­ç»ƒ {model_name}...\")\n",
    "    \n",
    "    # è®­ç»ƒæ¨¡å‹\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ä¿å­˜æ¨¡å‹\n",
    "    model_filename = os.path.join(save_path, f\"{model_name}_optimized_model.pkl\")\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"âœ… é‡æ–°è®­ç»ƒçš„ {model_name} å·²ä¿å­˜åˆ° {model_filename}\")\n",
    "# ğŸ“Œ 14ï¸âƒ£ ä¿å­˜è®­ç»ƒç»“æœåˆ° Excel\n",
    "results_df.to_excel(os.path.join(save_path, \"model_training_results.xlsx\"), index=False)\n",
    "print(\"\\nâœ… è®­ç»ƒç»“æœå·²ä¿å­˜åˆ° Excel æ–‡ä»¶ï¼\")\n",
    "\n",
    "# ğŸ“Œ 7ï¸âƒ£ è®­ç»ƒç‰¹å¾ä¿¡æ¯ DataFrame\n",
    "feature_info_df = pd.DataFrame({\n",
    "    \"Feature Name\": X_train.columns.tolist(),\n",
    "    \"Feature Index\": range(1, len(X_train.columns) + 1)\n",
    "})\n",
    "\n",
    "# ğŸ“Œ 8ï¸âƒ£ ä¿å­˜è®­ç»ƒç‰¹å¾ä¿¡æ¯\n",
    "feature_info_df.to_excel(os.path.join(save_path, \"training_feature_info.xlsx\"), index=False)\n",
    "print(\"\\nâœ… è®­ç»ƒç‰¹å¾ä¿¡æ¯å·²ä¿å­˜åˆ° training_feature_info.xlsx\")\n",
    "\n",
    "# ğŸ“Œ 9ï¸âƒ£ å±•ç¤ºä¿å­˜çš„æ¨¡å‹æ–‡ä»¶\n",
    "saved_models = os.listdir(save_path)\n",
    "print(\"\\nâœ… å·²æˆåŠŸä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ï¼š\", saved_models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "20250129",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
