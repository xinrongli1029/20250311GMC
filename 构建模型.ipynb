{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据维度: (44, 7)\n",
      "数据前几行: \n",
      "    KH550 (volume/mL)  temperature (℃)  Reaction time (h)  \\\n",
      "0                0.1               90                 12   \n",
      "1                0.5               90                 12   \n",
      "2                1.0               90                 12   \n",
      "3                1.5               90                 12   \n",
      "4                2.0               90                 12   \n",
      "\n",
      "   Protein incubation time (h)  Imidazole concentration (mM)  \\\n",
      "0                          2.0                           500   \n",
      "1                          2.0                           500   \n",
      "2                          2.0                           500   \n",
      "3                          2.0                           500   \n",
      "4                          2.0                           500   \n",
      "\n",
      "   Volume of imidazole (μL)  width (mm)  \n",
      "0                       600         0.3  \n",
      "1                       600         0.5  \n",
      "2                       600         0.5  \n",
      "3                       600         0.8  \n",
      "4                       600         1.0  \n",
      "Training ExtraTrees...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best parameters for ExtraTrees: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Training AdaBoost...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters for AdaBoost: {'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 200}\n",
      "Training RandomForest...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best parameters for RandomForest: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "Training GradientBoosting...\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best parameters for GradientBoosting: {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training KNN...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters for KNN: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "              Model        R²       MAE      RMSE        EV\n",
      "0        ExtraTrees  0.887536  0.266177  0.360497  0.933032\n",
      "1          AdaBoost  0.935361  0.222322  0.273302  0.950940\n",
      "2      RandomForest  0.898004  0.273904  0.343310  0.923192\n",
      "3  GradientBoosting  0.810009  0.369483  0.468556  0.812810\n",
      "4               KNN  0.823090  0.363517  0.452138  0.846229\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r'E:\\Desktop\\论文\\莫愁师姐\\磁性氧化铝分离蛋白(6).csv'\n",
    "df = pd.read_csv(file_path, encoding='gbk')  # 尝试使用 GBK 编码\n",
    "print('数据维度:', df.shape)\n",
    "# 数据文件路径\n",
    "data_path = r'E:\\Desktop\\论文\\莫愁师姐\\磁性氧化铝分离蛋白(6).csv'\n",
    " \n",
    "# 加载数据\n",
    "data = pd.read_csv(data_path, encoding='gbk')\n",
    " \n",
    "# 划分特征和标签\n",
    "X = data.iloc[:, :-1]  # 从第一列到倒数第二列提取特征\n",
    "y = data.iloc[:, -1]   # 最后一列作为目标变量\n",
    "# 确保所有特征名称都是字符串并移除特殊字符\n",
    "df.columns = df.columns.astype(str).str.replace('[', '', regex=False).str.replace(']', '', regex=False).str.replace('<', '', regex=False)\n",
    "\n",
    "# 打印前几行数据\n",
    "print(\"数据前几行: \\n\", df.head())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2048)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "\n",
    "# 定义模型（新增 KNN 和 SVR）\n",
    "models = {\n",
    "    'ExtraTrees': ExtraTreesRegressor(random_state=2048),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=2048),\n",
    "    'RandomForest': RandomForestRegressor(random_state=2048),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=2048),\n",
    "    'KNN': KNeighborsRegressor(),           # 新增 KNN\n",
    "}\n",
    "\n",
    "# 超参数网格（新增 KNN 和 SVR）\n",
    "param_grids = {\n",
    "    'ExtraTrees': {\n",
    "        'n_estimators': [10, 20, 100],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'max_depth': [None, 5, 10, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2, 1.0],\n",
    "        'loss': ['linear', 'square', 'exponential']\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "}\n",
    "\n",
    "# 存储结果\n",
    "results = []\n",
    "\n",
    "# 遍历模型，调参与评估\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # 网格搜索\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # 最优模型和参数\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "\n",
    "    # 预测\n",
    "    y_pred_test = best_estimator.predict(X_test)\n",
    "\n",
    "    # 计算 Root MAPE（避免除以 0）\n",
    "    non_zero_idx = y_test != 0\n",
    "    if np.any(non_zero_idx):\n",
    "        mape = np.mean(np.abs((y_test[non_zero_idx] - y_pred_test[non_zero_idx]) / y_test[non_zero_idx])) * 100\n",
    "        root_mape = np.sqrt(mape)  # 计算均方根 MAPE\n",
    "    else:\n",
    "        root_mape = np.nan\n",
    "\n",
    "    # 计算其他指标\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    ev = explained_variance_score(y_test, y_pred_test)\n",
    "\n",
    "    # 存储结果\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'R²': r2,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'EV': ev\n",
    "    })\n",
    "\n",
    "# 转换为 DataFrame 展示\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 打印结果\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据维度: (44, 7)\n",
      "\n",
      "🚀 正在重新训练 ExtraTrees...\n",
      "✅ 重新训练的 ExtraTrees 已保存到 E:\\Desktop\\莫愁师姐平台部署\\训练模型\\ExtraTrees_optimized_model.pkl\n",
      "\n",
      "🚀 正在重新训练 AdaBoost...\n",
      "✅ 重新训练的 AdaBoost 已保存到 E:\\Desktop\\莫愁师姐平台部署\\训练模型\\AdaBoost_optimized_model.pkl\n",
      "\n",
      "🚀 正在重新训练 RandomForest...\n",
      "✅ 重新训练的 RandomForest 已保存到 E:\\Desktop\\莫愁师姐平台部署\\训练模型\\RandomForest_optimized_model.pkl\n",
      "\n",
      "🚀 正在重新训练 GradientBoosting...\n",
      "✅ 重新训练的 GradientBoosting 已保存到 E:\\Desktop\\莫愁师姐平台部署\\训练模型\\GradientBoosting_optimized_model.pkl\n",
      "\n",
      "🚀 正在重新训练 KNN...\n",
      "✅ 重新训练的 KNN 已保存到 E:\\Desktop\\莫愁师姐平台部署\\训练模型\\KNN_optimized_model.pkl\n",
      "\n",
      "✅ 训练结果已保存到 Excel 文件！\n",
      "\n",
      "✅ 训练特征信息已保存到 training_feature_info.xlsx\n",
      "\n",
      "✅ 已成功保存的模型文件： ['AdaBoost_optimized_model.pkl', 'ExtraTrees_optimized_model.pkl', 'GradientBoosting_optimized_model.pkl', 'KNN_optimized_model.pkl', 'model_training_results.xlsx', 'RandomForest_optimized_model.pkl', 'training_feature_info.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# 重新加载必要的库\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "file_path = r'E:\\Desktop\\论文\\莫愁师姐\\磁性氧化铝分离蛋白(6).csv'\n",
    "df = pd.read_csv(file_path, encoding='gbk')  # 尝试使用 GBK 编码\n",
    "print('数据维度:', df.shape)\n",
    "# 数据文件路径\n",
    "data_path = r'E:\\Desktop\\论文\\莫愁师姐\\磁性氧化铝分离蛋白(6).csv'\n",
    "\n",
    "# 📌 2️⃣ 确保正确划分 6 个特征和 1 个目标变量\n",
    "X = df.iloc[:, :-1]  # 前 6 列是特征\n",
    "y = df.iloc[:, -1]   # 最后一列是目标变量 (width mm)\n",
    "\n",
    "# 📌 3️⃣ 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 📌 4️⃣ 使用找到的最优参数重新训练模型\n",
    "optimal_models = {\n",
    "    'ExtraTrees': ExtraTreesRegressor(\n",
    "        max_depth=10, max_features='sqrt', min_samples_leaf=1, min_samples_split=2, n_estimators=10, random_state=2048\n",
    "    ),\n",
    "    'AdaBoost': AdaBoostRegressor(\n",
    "        learning_rate=0.01, loss='square', n_estimators=200, random_state=2048\n",
    "    ),\n",
    "    'RandomForest': RandomForestRegressor(\n",
    "        bootstrap=False, max_depth=None, max_features='sqrt', min_samples_leaf=1, min_samples_split=5, n_estimators=500, random_state=2048\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingRegressor(\n",
    "        learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100, random_state=2048\n",
    "    ),\n",
    "    'KNN': KNeighborsRegressor(\n",
    "        n_neighbors=3, p=1, weights='distance'\n",
    "    ),\n",
    "}\n",
    "\n",
    "# 📌 5️⃣ 定义模型保存路径\n",
    "save_path = \"E:\\Desktop\\莫愁师姐平台部署\\训练模型\"\n",
    "os.makedirs(save_path, exist_ok=True)  # 创建文件夹（如果不存在）\n",
    "\n",
    "# 📌 6️⃣ 重新训练并保存模型\n",
    "for model_name, model in optimal_models.items():\n",
    "    print(f\"\\n🚀 正在重新训练 {model_name}...\")\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 保存模型\n",
    "    model_filename = os.path.join(save_path, f\"{model_name}_optimized_model.pkl\")\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"✅ 重新训练的 {model_name} 已保存到 {model_filename}\")\n",
    "# 📌 14️⃣ 保存训练结果到 Excel\n",
    "results_df.to_excel(os.path.join(save_path, \"model_training_results.xlsx\"), index=False)\n",
    "print(\"\\n✅ 训练结果已保存到 Excel 文件！\")\n",
    "\n",
    "# 📌 7️⃣ 训练特征信息 DataFrame\n",
    "feature_info_df = pd.DataFrame({\n",
    "    \"Feature Name\": X_train.columns.tolist(),\n",
    "    \"Feature Index\": range(1, len(X_train.columns) + 1)\n",
    "})\n",
    "\n",
    "# 📌 8️⃣ 保存训练特征信息\n",
    "feature_info_df.to_excel(os.path.join(save_path, \"training_feature_info.xlsx\"), index=False)\n",
    "print(\"\\n✅ 训练特征信息已保存到 training_feature_info.xlsx\")\n",
    "\n",
    "# 📌 9️⃣ 展示保存的模型文件\n",
    "saved_models = os.listdir(save_path)\n",
    "print(\"\\n✅ 已成功保存的模型文件：\", saved_models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "20250129",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
